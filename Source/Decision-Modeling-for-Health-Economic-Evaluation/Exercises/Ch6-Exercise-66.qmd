# Exercise 6.6A & 6.6B {.unnumbered}

This section reproduces exercise 6.6a and 6.6b in R from Chapter 6 in the book "Decision Modelling for Health Economic Evaluation" by Andrew Briggs, Mark Sculpher, and Karl Claxton.

#Exercise 6.6A

## Setup
Much of the code will come from exercise 5.8. In this exercise, we will use the simulation results to calculate the expected value of perfect information (EVPI). In this first code chunk we bring over all the previous functions that generated the cost effectiveness data for each of the prosthesis interventions considered in exercise 5.8. 

In this case, we are only focusing on the standard prosthesis and the "new prosthesis" NP1. So the values for NP2 will ignored for now.

```{r 6.6A.0 Setup parameters}
library(MASS)

#fixed parameters

cStandard <- 394 #cost of standard prosthesis
cNP1 <- 579 #cost of new prosthesis 1

cDR <- 0.06 #cost discount rate
oDR <- 0.015 #outcome discount rate
age <- 60 #average age of all patients at receipt of primary implant
male <- 0 #sex indicator (0 for female, 1 for male)

iVec <- c(1000,0,0,0,0) #starting vector; everyone starts in the first state
t <- 60 #number of cycles

covMat <- matrix(
  c(0.0022515  , -0.005691 ,  0.000000028,  0.0000051,  0.000259 ,
   -0.005691   ,  0.0432191, -0.000783   , -0.007247 , -0.000642 ,
    0.000000028, -0.000783 ,  2.716e-05  ,  0.000033 , -0.000111 ,
    0.0000051  , -0.007247 ,  0.000033   ,  0.0118954,  0.000184 ,
    0.000259   , -0.000642 , -0.000111   ,  0.000184 ,  0.1463686
   ),
  nrow = 5, ncol = 5, byrow = T
)

colnames(covMat) <- rownames(covMat) <- c("lngamma","cons","age","male","NP1")

survModelSummary <- data.frame(
  variable = c("lngamma","cons","age","male","NP1"),
  coefficient = c(0.3740968,-5.490935,-0.0367022,0.768536,-1.344474),
  SE = c(0.0474501,0.207892,0.0052112,0.109066,0.3825815)
)

survModelSummary$hazard_ratio <- exp(survModelSummary$coefficient)

#if we need cholesky decomposition
cholcovMat <- chol(covMat)

#fixed mortality rates and transition probabilities
deathRates <- data.frame(
  Age = c("35-44","45-54","55-64","65-74","75-84","85 and over"),
  Males = c(1.51,3.93,10.9,31.6,80.1,187.9),
  Females = c(0.99,2.6,6.7,19.3,53.5,154.8)
)

yearlyTProbs <- data.frame(
    Age = c("35-44","45-54","55-64","65-74","75-84","85 and over"),
    Index = c(35,45,55,65,75,85),
    Males = c(0.00151,0.00393,0.0109,0.0316,0.0801,0.1879),
    Females = c(0.00099,0.0026,0.0067,0.0193,0.0535,0.1548)
)

```


Now we will bring in all the previous functions relevant to the NP1 analysis.
```{r 6.6A.0 Bring in helper functions}
discountFormula <- function(nonDiscount,discRate,t){
  
  return(nonDiscount/(1+discRate)^(1:t))
  
}

drawBetaMethodMoments <- function(n,mu,s){
  
  #functions estimates alpha and beta using the method of moments then draws from the beta distribution
  alpha <- ((mu*(1-mu)/s^2) -1)*mu
  beta <- alpha*(1-mu )/mu
  
  #draw our random number
  draw <- rbeta(n,alpha,beta)
  
  return(draw)
}


tProbsHazard <- function(t,lambda,gamma){
  
  return(1-exp(lambda*(((1:t)-1)^gamma - ((1:t)^gamma))))
  
}

tProbs_time <- function(omrPTHR,omrRTHR,rr,mr,rrr,t){
  #rr is revision risk, mr is mortality risk
  
  tProbs <- matrix(
  c(0, 1-(omrPTHR),     0,     0,                   omrPTHR,
    0, 1-(rr[t]+mr[t]), rr[t], 0,                   mr[t],
    0, 0,               0,     1-(omrRTHR + mr[t]), omrRTHR + mr[t],
    0, 0,               rrr,   1-(rrr+mr[t]),       mr[t],
    0, 0,               0,     0,                   1
  ),ncol = 5, nrow = 5, byrow = T
)
  
}


calculateYearlyProbs <- function(iVec,omrPTHR,omrRTHR,rr,mr,rrr,t){
  
  #create empty matrix that we will fill in
  
  matReturn <- matrix(nrow = t, ncol = 5)
  
  #initialize first vector of proportions
  
  #create column names
  colnames(matReturn) <- c("PrimaryTHR","SuccessP","RevisionTHR","SucessR","Death")

  for(i in 1:t){
    
    #get the corresponding transition matrix based on the time
    tProbs <- tProbs_time(omrPTHR,omrRTHR,rr,mr,rrr,i)
    
    matReturn[i,] <-   iVec %*% tProbs #round because we are using full population units
    
    #update ivec
    iVec <- iVec %*% tProbs
    
  }
  return(matReturn)
  
  #returns a t (years) x 5 (states) matrix where the rows represent the proportion in a given state at year t
  
}

analysisNP1 <- function(omrPTHR,omrRTHR,mr,rrr,rrNP1,cPrimary,cRevision,cStandard,uSuccessP,uSuccessR,uRevision,cDR,oDR,cNP1,gamma,lambda,iVec,t){

    #calculate the revision risk
    rr <- tProbsHazard(t=t,lambda = lambda,gamma = gamma)
    
    mr <- sapply(1:t,function(x){
    
    #calculate which index select based on the age group
    inds <- sum(x+age >= yearlyTProbs$Index)
    
    #select the gender columns
    #if else takes 3 arguments, the first is a logical check, if true, it returns the second value, if false it returns the 3rd argument. Equivalent code can be written use if(x){}else{}.
    genderCol <- ifelse(male ==1,3,4)
    
    return(yearlyTProbs[inds,genderCol])
    
  })
    
  #calculate standard states
  standPopStates <- calculateYearlyProbs(iVec = iVec,omrPTHR=omrPTHR, omrRTHR=omrPTHR,rr= rr, mr = mr,rrr=rrr,t=t)
  lifeYearsStandard <- rowSums(standPopStates[,-5])
  #excludes death year
  costVec <- c(0,0,cRevision,0)

  #add a parameter for the initial cost we had 1000 initial patients
  iCostStandard <- cStandard*1000
  
  #first calculate the total cost
  totalCosts <- standPopStates[,-5] %*% costVec
  
  #calculate the discounted cost
  discCostStandard <- discountFormula(totalCosts,cDR,t=t)
  
  #calculate the quality adjusted life years by creating a vector for each state utility except death
  utility<- c(0,uSuccessP,uRevision,uSuccessR)
  
  #multiply by the cohort
  totalQuality <-  standPopStates[,-5] %*% utility
  QALYStandard <- discountFormula(totalQuality,discRate = oDR,t=t)
  
  #calculate the total cost for all cycles/person
  STDCost <- sum(c(iCostStandard,discCostStandard))/1000
  STDLYs <- sum(lifeYearsStandard)/1000
  STDQALYS <- sum(QALYStandard)/1000

  ###repeat this for the NP1###
  rrNP1_vec <- tProbsHazard(t,lambda = lambda*rrNP1,gamma = gamma)

  #call the previous function created
  populationStatesNP1 <- calculateYearlyProbs(iVec,omrPTHR,omrRTHR,rr=rrNP1_vec,mr=mr,rrr=rrr,t=t)
  
  #calculate life years for np1
  lifeYearsNP1 <- rowSums(populationStatesNP1[,-5])
  
  #total and discounted costs
  totalCostsNP1 <- populationStatesNP1[,-5] %*% costVec
  discCostsNP1 <- discountFormula(totalCostsNP1,cDR,t=t)
  #add the initial cost for NP1
  iCostNP1 <- cNP1*1000
  #Utility
  totalQualityNP1 <- populationStatesNP1[,-5] %*% utility
  QALYNP1 <- discountFormula(totalQualityNP1,discRate = oDR,t=t)
  
  #calculate the total cost for all cycles/person
  NP1Cost <- sum(c(iCostNP1,discCostsNP1))/1000
  NP1LYs <- sum(lifeYearsNP1)/1000
  NP1QALYS <- sum(QALYNP1)/1000
  
  #returns a list of discounted cost and QALYs for each method
  return(list(STDCost = STDCost, STDQALYS = STDQALYS, NP1Cost = NP1Cost,NP1QALYS = NP1QALYS, ICER = (NP1Cost-STDCost)/(NP1QALYS-STDQALYS)))
  
}

#generate simulation function
generateSimulations <- function(nReps = 1000,age=60,male=0,cRatio = 100000){
   
   #we need to know how many columns or variable we have here in ncol
   cols <- c("omrPTHR","omrRTHR","rrNP1","rrr","lambda","gamma",
             "cPrimary","cRevision","cSuccess","uSuccessP","uSuccessR",
             "uRevision","cRatio","STDCost","STDQALYS","NP1Cost","NP1QALYS",
             "STDNMB","NP1NMB","NP1Inc","CESTD","CENP1","CENP1Inc")
   
   #initialize our return dataframe
   dfReturn <- data.frame(matrix(NA, nrow = nReps, ncol = length(cols)))
  
   #fill out the column names for our dataframe
   colnames(dfReturn) <- cols

   #cRatio is fixed at 10000
   dfReturn$cRatio <- cRatio
   alpha <- (5294/1487)^2
   beta <- 1487^2 / 5294
   
   
   #due to R's vectorization, we can sample all the parameters at once in the "n" parameter
   omrPTHR <- rbeta(nReps,2,98) #operative mortality rate following primary THR
   omrRTHR <- rbeta(nReps,2,98) #operative mortality rate following revision THR
   rrr <- rbeta(nReps,4,96) #re-revision risk
   
   #save them here using R's vectorization
   dfReturn$omrPTHR <- omrPTHR
   dfReturn$omrRTHR <- omrRTHR 
   dfReturn$rrr <- rrr
   
   #cost and utility
   cRevision <- rgamma(nReps,shape = alpha,scale = beta)
   uSuccessP <- drawBetaMethodMoments(nReps,0.85,0.03)
   uSuccessR <- drawBetaMethodMoments(nReps,0.75,0.04)
   uRevision <- drawBetaMethodMoments(nReps,0.3,0.03)
   
   dfReturn$cRevision <- cRevision
   dfReturn$uSuccessP <- uSuccessP
   dfReturn$uSuccessR <- uSuccessR
   dfReturn$uRevision <- uRevision 
   
   #draw from multivariate normal
   normDraw <- MASS::mvrnorm(nReps, mu = survModelSummary$coefficient,Sigma = covMat)
   
   #using R's vectorization, we can calculate operations on the entire vector, we must use [,"name"]as normDraw is not a matrix rather than a vector
   lambda <- exp(normDraw[,'cons'] + normDraw[,'age']*age + normDraw[,'male']*male)
   gamma <- exp(normDraw[,'lngamma'])
   rrNP1 <- exp(normDraw[,'NP1'])
   
   dfReturn$lambda <- lambda
   dfReturn$gamma <- gamma
   dfReturn$rrNP1 <- rrNP1

  #start the for-loop
  
  for(i in 1:nReps){
    
    #call the analysis function and specify the iteration for the parameter to be selected
    #those with a parameter that is constant do not need to be called from dfReturn
    results <- analysisNP1(dfReturn$omrPTHR[i],dfReturn$omrRTHR[i],mr,dfReturn$rrr[i],dfReturn$rrNP1[i],cPrimary,dfReturn$cRevision[i],cStandard,dfReturn$uSuccessP[i],dfReturn$uSuccessR[i],dfReturn$uRevision[i],cDR,oDR,cNP1,dfReturn$gamma[i],dfReturn$lambda[i],iVec,t)
    
    #save the results
    dfReturn$STDCost[i] <- results$STDCost
    dfReturn$STDQALYS[i] <- results$STDQALYS
    dfReturn$NP1Cost[i] <- results$NP1Cost
    dfReturn$NP1QALYS[i] <- results$NP1QALYS
    
    #calculate net monetary benefit
    dfReturn$STDNMB[i] <- results$STDQALYS*dfReturn$cRatio[i]-results$STDCost
    dfReturn$NP1NMB[i] <- results$NP1QALYS*dfReturn$cRatio[i]-results$NP1Cost
    dfReturn$NP1Inc[i] <- (results$NP1QALYS-results$STDQALYS)*dfReturn$cRatio[i] - (results$NP1Cost-results$STDCost)
    
    #calculate the cost effectiveness
    dfReturn$CESTD[i] <- ifelse(dfReturn$STDNMB[i]>= dfReturn$NP1NMB[i],1,0)
    dfReturn$CENP1[i] <- ifelse(dfReturn$CESTD[i]==1,0,1)
    dfReturn$CENP1Inc[i] <- ifelse(dfReturn$NP1Inc[i]>0,1,0)
    
    #the above formulae come directly from the textbook 5.1.4
  }
  return(dfReturn)
}

```

## Part 1: Calculating net monetary benefit

We will start the simulation the way as in Exercise 5.7 and 5.8. Then we will calculate the mean net monetary benefit for the standard and NP1 treatment; the maximum net monetary benefit; and the maximum net monetary benefit under perfect information. 

Net monetary benefit is often referred to as NMB. We use this initialism in the R code below.
```{r 6.6A.1 run the simulation}

set.seed(123)
cRatio <- 100000

simResults <- generateSimulations(nReps = 10000,cRatio = cRatio)
```

We will calculate the mean and and maximum net monetary benefit
```{r 6.6A.1 calculating mean and maximum NMB}
#simplest using colMeans
meanNMB <- colMeans(simResults[,c("STDNMB","NP1NMB")])

#get the maximum NMB within each treatment iteration
maxPINMB <- pmax(simResults[,c("STDNMB")],simResults[,c("NP1NMB")])
```

Now we can calculate the EVPI which is: 
$$
E_{\theta} [\max_j \text{NMB}(j,\theta)]- \max_j E_{\theta}[\text{NMB}(j,\theta)]
$$
For this exercise, we only need the STD and NP1 columns.
```{r 6.6A.1 Calculate EVPI}

EVPI <- mean(maxPINMB)-max(meanNMB) 

EVPI 
```

This is the expected value of information for a given patient. 

## Part 2: Calculating the EVPI at the population level

Next, we aim to calculate the EVPI at the population level by multiplying by the population, applying discounting for future years.

```{r 6.6A.2 EVPI at the population level 1}
annualPop <- 40000

#discounted population
discPop <- discountFormula(annualPop,cDR,9)
```

Now we calculate the sum of the population years and multiply the result by the per person EVPI to get the population-level EVPI, here labeled `popEVPI`.
```{r 6.6A.2 EVPI at the population level 2}
perAnnumEffPop <- sum(c(annualPop,discPop))


popEVPI <- EVPI*perAnnumEffPop


popEVPI 
```

## Part 3: Plotting EVPI

We will visualize our results by plotting the EVPI by the cost-effectiveness threshold ratio `cRatio`. 

Here we run the simulation loop by sequencing through cRatio to plot the curve. We may use the sapply family of functions.
```{r 6.6A.3 plotting EVPI}
library(ggplot2)
#calculate the cRatios to be looped over
cRatios <- seq(0,50000,by = 500)
  annualPop <- 40000


#using the same sapply function as before
cRatioResults <- sapply(cRatios,function(x){
  
  #call the simulation
  NP1sim <- generateSimulations(nReps = 1000,cRatio = x)
  
  #simplest using colMeans
  meanNMB <- colMeans(NP1sim[,c("STDNMB","NP1NMB")])
  #get the maximum NMB within each treatment iteration
  maxPINMB <- pmax(NP1sim[,c("STDNMB")],NP1sim[,c("NP1NMB")])
  
  EVPI <- mean(maxPINMB)-max(meanNMB) 
    
  #multiply EVPI by discounted population
  popEVPI <- EVPI*perAnnumEffPop

  return(popEVPI)
})
```

Now, we compile our results in a data frame
```{r 6.6A.3 save EVPI and cRatios in a dataframe}
dfEVPI <- data.frame(cRatio = cRatios, EVPI = cRatioResults)
```

Lastly, we plot the population EVPI by the cRatio using `ggplot2`
```{r 6.6A.3 plot EVPI & cRatio results}
#load package
library("ggplot2")

#specify plot 
ggplot2::ggplot(dfEVPI,
                aes(
                  x = cRatio, 
                  y = EVPI)) + 
                geom_line(
                  colour = "#414487",
                  linewidth = 1.5) + 
                labs(
                  x = "Ceiling Ratio",
                  y = "Population EVPI", 
                  title = "EVPI by cRatio")
```

# Exercise 6.6B

In the section of this exercise we will investigate the EVPI of grouped parameters. Based on the previous plot, to maximize the EVPI for a given cRatio, we should pick cRatio = 2200. This is the value provided by the textbook that maximizes the EVPI, however, due to Monte Carlo variability the empirical value here will be different, and different for each seed used.

## Part 1: Calculating the expected value of perfect information for parameters (EVPPI)

Recall that the Expected Value of Perfect information for Parameters (EVPPI) for some parameter $\phi$, where $\theta = \phi \cup \psi$ is

$$
 E_\phi\max_j[E_{\psi|\phi}[NMB(j,\phi,\psi)]- \max_j E_{\theta}[\text{NMB}(j,\theta)].
$$
First, if we wanted to use the results from our simulation above, we could use the `which.max` function to select the element from `cRatios` that corresponds to the largest value in the `cRatioResults` we calculated in 6.6A.

```{r 6.6B.1 Parameter information with rrNP1}
cRatios[which.max(cRatioResults)]
```

While, the textbook states 2200, due to variability in the simulations, a larger number of repetitions and finer grid of cRatios would better approximate the maximum.

Despite this, we will use the textbook value of 2200.
```{r 6.6B.1 set cRatio value}
cRatio <- 2200
```

We can capture the value of information for a certain parameter by fixing that parameter before the simulation. To make these changes, we must make some alterations to the `generateSimulations` function. 

The main alteration is by adding a `keepFixed` argument. Here, `keepFixed` determines which parameters are held constant in the simulation. For the fixed parameter, the first element [1] is used as the “fixed” value. All other parameters not chosen by `keepFixed` vary as before through draws from distributions.

```{r 6.6b.1}
generateSimulationsParam <- function(nReps = 1000,age=60,male=0,cRatio = 100000, keepFixed = "rrNP1"){
  
  
   #we need to know how many columns or variable we have here in ncol
   cols <- c("omrPTHR","omrRTHR","rrNP1","rrr","lambda","gamma",
             "cPrimary","cRevision","cSuccess","uSuccessP","uSuccessR",
             "uRevision","cRatio","STDCost","STDQALYS","NP1Cost","NP1QALYS",
             "STDNMB","NP1NMB","NP1Inc","CESTD","CENP1","CENP1Inc")
   
   #initialize our return dataframe
   dfReturn <- data.frame(matrix(NA, nrow = nReps, ncol = length(cols)))
  
   #fill out the column names for our dataframe
   colnames(dfReturn) <- cols
   
   
   #cRatio is fixed at 10000
   dfReturn$cRatio <- cRatio
   alpha <- (5294/1487)^2
   beta <- 1487^2 / 5294
   
   
   #due to R's vectorization, we can sample all the parameters at once in the "n" parameter
   omrPTHR <- rbeta(nReps,2,98) #operative mortality rate following primary THR
   omrRTHR <- rbeta(nReps,2,98) #operative mortality rate following revision THR
   rrr <- rbeta(nReps,4,96) #re-revision risk
   
   #save them here using R's vectorization
   dfReturn$omrPTHR <- omrPTHR
   dfReturn$omrRTHR <- omrRTHR 
   dfReturn$rrr <- rrr
   
   #cost and utility
   cRevision <- rgamma(nReps,shape = alpha,scale = beta)
   uSuccessP <- drawBetaMethodMoments(nReps,0.85,0.03)
   uSuccessR <- drawBetaMethodMoments(nReps,0.75,0.04)
   uRevision <- drawBetaMethodMoments(nReps,0.3,0.03)
   
   dfReturn$cRevision <- cRevision
   dfReturn$uSuccessP <- uSuccessP
   dfReturn$uSuccessR <- uSuccessR
   dfReturn$uRevision <- uRevision 
   
   #draw from multivariate normal
   normDraw <- MASS::mvrnorm(nReps, mu = survModelSummary$coefficient,Sigma = covMat)
   
   #using R's vectorization, we can calculate operations on the entire vector, we must use [,"name"]as normDraw is not a matrix rather than a vector
   lambda <- exp(normDraw[,'cons'] + normDraw[,'age']*age + normDraw[,'male']*male)
   gamma <- exp(normDraw[,'lngamma'])
   rrNP1 <- exp(normDraw[,'NP1'])
   
   dfReturn$lambda <- lambda
   dfReturn$gamma <- gamma
   dfReturn$rrNP1 <- rrNP1

  #start the for-loop
    
    #choose which parameter will be kept fixed based on the first draw
    if(keepFixed == "rrNP1"){
      
      dfReturn$rrNP1 <- rrNP1[1]
    }else if(keepFixed == "OMRs"){
      
      dfReturn$omrPTHR <- omrPTHR[1]
      dfReturn$omrRTHR <- omrRTHR[1]   
      
    }else if(keepFixed == "cRevision"){
      dfReturn$cRevision <- cRevision[1]
      
    }else if(keepFixed == "rrr"){
      
        dfReturn$rrr <- rrr[1]
      
    }else if(keepFixed == "utilities"){
      
        dfReturn$uSuccessP <- uSuccessP[1]
        dfReturn$uRevision <- uRevision[1]
        dfReturn$uSuccessR <- uSuccessR[1]
    }else if(keepFixed == "survParams"){
      
        dfReturn$lambda <- lambda[1]
        dfReturn$gamma <- gamma[1]
      
      
    }

  for(i in 1:nReps){

    results <- analysisNP1(dfReturn$omrPTHR[i],dfReturn$omrRTHR[i],mr,dfReturn$rrr[i],dfReturn$rrNP1[i],cPrimary,dfReturn$cRevision[i],cStandard,dfReturn$uSuccessP[i],dfReturn$uSuccessR[i],dfReturn$uRevision[i],cDR,oDR,cNP1,dfReturn$gamma[i],dfReturn$lambda[i],iVec,t)
    
    #save the results, including NP2
    dfReturn$STDCost[i] <- results$STDCost
    dfReturn$STDQALYS[i] <- results$STDQALYS
    dfReturn$NP1Cost[i] <- results$NP1Cost
    dfReturn$NP1QALYS[i] <- results$NP1QALYS
    #dfReturn$NP2Cost[i] <- results$NP2cost
    #dfReturn$NP2QALYS[i] <- results$NP2QALYS
    
    
    #calculate net monetary benefit, we now remove the redundant  "NP1 inc"
    dfReturn$STDNMB[i] <- results$STDQALYS*dfReturn$cRatio[i]-results$STDCost
    dfReturn$NP1NMB[i] <- results$NP1QALYS*dfReturn$cRatio[i]-results$NP1Cost
    dfReturn$NP1Inc[i] <- (results$NP1QALYS-results$STDQALYS)*dfReturn$cRatio[i] - (results$NP1Cost-results$STDCost)
    
    #dfReturn$NP2NMB[i] <- results$NP2QALYS*dfReturn$cRatio[i]-results$NP2cost    
    #calculate the cost effectiveness. Note with 3 methods, we must take the maximum 
    bestTreatment <- max(dfReturn$STDNMB[i], dfReturn$NP1NMB[i], dfReturn$NP2NMB[i] )
   
    #save the cost effectiveness winner
    dfReturn$CISTD[i] <- ifelse(dfReturn$STDNMB[i]==bestTreatment,1,0)
    dfReturn$CINP1[i] <- ifelse(dfReturn$NP1NMB[i]==bestTreatment,1,0)
    dfReturn$CINP1Inc[i] <- ifelse(dfReturn$NP1Inc[i]>0,1,0)
    #dfReturn$CINP2[i] <- ifelse(dfReturn$NP2NMB[i]==bestTreatment,1,0)

  }
  
  return(dfReturn)
}


#we repeat this 100 or (many times), while keeping the rrNP1 fixed

fixrrNP1 <- t(sapply(1:100,function(x){
  
  
  simResults <- generateSimulationsParam(cRatio = 2200,keepFixed = "rrNP1",nReps = 1000)
  meanBenefit <- colMeans(simResults[,c("STDNMB","NP1NMB")])
  
  
  return(meanBenefit)
  
}))
```

Then we calculate the expected maximum and adjust for the population and future discounting using the `perAnnumEffPop` value we calculated before.
```{r 6.6b.1 Calculate EVPI for the population}
#expected maximum
expMaxrrNP1 <- mean(pmax(fixrrNP1[,"STDNMB"],fixrrNP1[,"NP1NMB"]))
maxExpNP1 <- max(colMeans(fixrrNP1))

EVPI <- expMaxrrNP1-maxExpNP1

#adjust for discounting the population over time
EVPI_pop <- EVPI*perAnnumEffPop

EVPI_pop
```


## Part 2: Conducting EVPPI for all parameters

Now that we have established how to perform partial value of information by fixing one parameter, we can apply this to every set of parameters. 

We will loop through every parameter group while keeping it fixed while calculating the EVPI. Ideally we would want the number of trials and the number of repetitions to each be 1000 however this becomes quite computationally intensive. Using parallel processing would speed up this process significantly. In this section we first write the code only using sequential (base) processing but add the parallelized version in the appendix.

:::{.callout-tip}
In the loop below, the function `outerSimLoop` uses the vector `paramGroups `to hold all the parameter names that we want to loop through. This vector is passed as a default argument to the function, so it doesn’t need to be manually typed each time the function is called. Using a vector like this reduces the chance of typos or errors and makes the code more flexible and easier to maintain.
:::

```{r 6.6b.2 parameter looping}

outerSimLoop <- function(trials = 100,nReps=100,cRatio=2200, paramGroups = c("rrNP1","OMRs","cRevision","rrr","utilities","survParams")){
  
  #Run the simulation for each fixed parameter

  nParams <- length(paramGroups)  
  
  EVPIs <- data.frame(matrix(NA,nrow =1,ncol = nParams))
  ##set the column names to match our parameters of interest using paramGroups vector
  colnames(EVPIs) <- paramGroups

  for(p in 1:nParams){
    
    fixedParam <- paramGroups[p]
    print(fixedParam )
    
    #call the sapply function from earlier (also referred to as the "inner loop" in the excel file.)
    trialResults <- t(sapply(1:trials,function(x){
      
      #get the simulation results
      simResults <- generateSimulationsParam(cRatio = cRatio, keepFixed = fixedParam ,nReps = nReps)
      
      #get the mean benefit across the trials
      meanBenefit <- colMeans(simResults[,c("STDNMB","NP1NMB")])
      
      
      return(meanBenefit)
      
    }))

    #calculate the EVPI
    expMaxrrNP1 <- mean(pmax(trialResults[,"STDNMB"],trialResults[,"NP1NMB"]))
    maxExpNP1 <- max(colMeans(trialResults))
    
    EVPI <- expMaxrrNP1-maxExpNP1
    
    #adjust for discounting the population over time
    EVPI_pop <- EVPI*perAnnumEffPop
    
    #save the EVPI
    EVPIs[,p] <- EVPI_pop
    
  }
  
  #return
  return(EVPIs)
  
}
```

Here we only run the simulations of 100x100 this is already 100,000. Note that:

- **`trials`**: the number of times the simulation is run for each fixed parameter (outer loop).  
- **`nReps`**: the number of individual simulation replications within each trial (inner loop), used to estimate outcomes for that trial.  

```{r 6.6b.2 EVPPI simulation results}
EVPPI_simResults <- outerSimLoop(trials = 100,nReps=100,cRatio=2200, paramGroups = c("rrNP1","OMRs","cRevision","rrr","utilities","survParams"))

```

## Part 3: Ploting the results
Lastly, transform the dataframe and then plot the results of the the partial EVPI for each parameter
```{r plot the results}
##load tidyr package 
library(tidyr)
EVPPI_plotDF <- tidyr::pivot_longer(EVPPI_simResults,everything(),names_to = "paramGroup",values_to = "partialEVPI")

##load the viridis and scales package for colors and label formatting
library(viridis)
library(scales)

ggplot2::ggplot(EVPPI_plotDF,
       aes(
         x = paramGroup,
         y = partialEVPI,
         fill = paramGroup  # fill bars by parameter group
       )) +
  geom_bar(
    stat = "identity",
    colour = "grey4"     # dark outlines for contrast
  ) +
  scale_fill_viridis(
    discrete = TRUE,      # categorical variable
    option = "D"          # choose a viridis palette (A-D)
  ) +
  scale_y_continuous(labels = comma) +  # format y-axis numbers with commas
  labs(
    x = "Parameter Group",
    y = "Partial EVPI",
    title = "Expected value of partial perfect information by parameter group"
  ) +
  theme_minimal()+
   theme(
    legend.position = "none"  # hide legend if bars are self-explanatory
  )
```







